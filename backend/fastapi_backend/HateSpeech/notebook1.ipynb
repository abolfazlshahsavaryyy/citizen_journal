{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5328041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fd9ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def read_data(path):\n",
    "#     df = pd.read_csv(path)\n",
    "#     df = df.sample(frac=0.1, random_state=42)  # random_state for reproducibility\n",
    "#     df = df.reset_index(drop=True)  # Optional: reset index after sampling\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcc0df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='/home/abolfazl/Documents/CitizenJournal/citizen_journal/backend/fastapi_backend/HateSpeech/HateSpeechDatasetBalanced.csv'\n",
    "# df=read_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539471ea",
   "metadata": {},
   "source": [
    "### BertTokenizer: \n",
    " Splits and converts your input text (like a sentence) into tokens that BERT can understand.\n",
    "\n",
    "### BertModel:\n",
    " The actual pre-trained BERT model that turns the tokens into useful numeric vectors (called embeddings).\n",
    "\n",
    "### bert-base-uncased:\n",
    " A version of BERT that has been trained on English text, where all words are lowercase.\n",
    "\n",
    "### model.eval():\n",
    " Tells the model to run in inference mode (not training mode). This saves memory and speeds up processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3768292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# model.eval()  # inference mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f5ca9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cls_embedding(text):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "#     return cls_embedding.squeeze().numpy()  # shape: (768,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "810c0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = []\n",
    "\n",
    "# for text in tqdm(df['Content'], desc=\"Extracting BERT embeddings\"):\n",
    "#     try:\n",
    "#         vector = get_cls_embedding(text)\n",
    "#         embeddings.append(vector)\n",
    "#     except Exception as e:\n",
    "#         embeddings.append(None)  # in case of any failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "402c65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the list of embeddings into a DataFrame\n",
    "# embedding_df = pd.DataFrame(embeddings)\n",
    "\n",
    "# # Rename the columns before merging\n",
    "# embedding_df.columns = [f'embedding_{i}' for i in range(embedding_df.shape[1])]\n",
    "\n",
    "# # Merge with the original DataFrame\n",
    "# df = pd.concat([df, embedding_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ddae5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = '/home/abolfazl/Documents/CitizenJournal/citizen_journal/backend/fastapi_backend/HateSpeech/embedded_data.csv'\n",
    "# df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a745b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_758</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you should be deeply embarrassed... by not ful...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278104</td>\n",
       "      <td>0.333025</td>\n",
       "      <td>-0.294160</td>\n",
       "      <td>-0.145966</td>\n",
       "      <td>-0.485665</td>\n",
       "      <td>-0.786977</td>\n",
       "      <td>0.459131</td>\n",
       "      <td>0.544359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046933</td>\n",
       "      <td>-0.309165</td>\n",
       "      <td>-0.127641</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-0.140215</td>\n",
       "      <td>0.193676</td>\n",
       "      <td>-0.034632</td>\n",
       "      <td>-0.019996</td>\n",
       "      <td>0.560498</td>\n",
       "      <td>0.340829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do not make me make you fall in love with a bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.133017</td>\n",
       "      <td>0.202193</td>\n",
       "      <td>-0.421173</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>-0.201444</td>\n",
       "      <td>-0.419096</td>\n",
       "      <td>0.644618</td>\n",
       "      <td>0.595702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270720</td>\n",
       "      <td>-0.357238</td>\n",
       "      <td>0.121133</td>\n",
       "      <td>-0.065833</td>\n",
       "      <td>0.152818</td>\n",
       "      <td>0.050402</td>\n",
       "      <td>0.077813</td>\n",
       "      <td>-0.305431</td>\n",
       "      <td>-0.050150</td>\n",
       "      <td>0.260495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump america is anti immigrant sexual activit...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.138762</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>-0.092694</td>\n",
       "      <td>-0.007501</td>\n",
       "      <td>-0.443966</td>\n",
       "      <td>-0.109705</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>0.544135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178341</td>\n",
       "      <td>-0.271666</td>\n",
       "      <td>0.061014</td>\n",
       "      <td>0.067001</td>\n",
       "      <td>0.656415</td>\n",
       "      <td>0.115183</td>\n",
       "      <td>-0.189214</td>\n",
       "      <td>-0.475422</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.382447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you guys are clearly a pole smoker please get ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406987</td>\n",
       "      <td>0.299873</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>-0.191551</td>\n",
       "      <td>-0.434151</td>\n",
       "      <td>-0.539173</td>\n",
       "      <td>0.511990</td>\n",
       "      <td>0.659850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.406413</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.162931</td>\n",
       "      <td>0.342772</td>\n",
       "      <td>-0.140089</td>\n",
       "      <td>-0.001462</td>\n",
       "      <td>-0.489326</td>\n",
       "      <td>0.283278</td>\n",
       "      <td>0.042651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh come along the only reason people like stri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209989</td>\n",
       "      <td>0.294031</td>\n",
       "      <td>0.037456</td>\n",
       "      <td>-0.131755</td>\n",
       "      <td>-0.274220</td>\n",
       "      <td>-0.452337</td>\n",
       "      <td>0.039897</td>\n",
       "      <td>0.521467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015279</td>\n",
       "      <td>-0.253148</td>\n",
       "      <td>-0.329311</td>\n",
       "      <td>-0.145785</td>\n",
       "      <td>0.218858</td>\n",
       "      <td>0.116727</td>\n",
       "      <td>-0.372996</td>\n",
       "      <td>-0.278894</td>\n",
       "      <td>0.474181</td>\n",
       "      <td>0.245281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Label  embedding_0  \\\n",
       "0  you should be deeply embarrassed... by not ful...      1     0.278104   \n",
       "1  do not make me make you fall in love with a bi...      0    -0.133017   \n",
       "2  trump america is anti immigrant sexual activit...      1    -0.138762   \n",
       "3  you guys are clearly a pole smoker please get ...      1     0.406987   \n",
       "4  oh come along the only reason people like stri...      0     0.209989   \n",
       "\n",
       "   embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0     0.333025    -0.294160    -0.145966    -0.485665    -0.786977   \n",
       "1     0.202193    -0.421173    -0.009662    -0.201444    -0.419096   \n",
       "2     0.005806    -0.092694    -0.007501    -0.443966    -0.109705   \n",
       "3     0.299873     0.009246    -0.191551    -0.434151    -0.539173   \n",
       "4     0.294031     0.037456    -0.131755    -0.274220    -0.452337   \n",
       "\n",
       "   embedding_6  embedding_7  ...  embedding_758  embedding_759  embedding_760  \\\n",
       "0     0.459131     0.544359  ...       0.046933      -0.309165      -0.127641   \n",
       "1     0.644618     0.595702  ...       0.270720      -0.357238       0.121133   \n",
       "2     0.614334     0.544135  ...      -0.178341      -0.271666       0.061014   \n",
       "3     0.511990     0.659850  ...      -0.038749      -0.406413       0.051500   \n",
       "4     0.039897     0.521467  ...      -0.015279      -0.253148      -0.329311   \n",
       "\n",
       "   embedding_761  embedding_762  embedding_763  embedding_764  embedding_765  \\\n",
       "0      -0.448980      -0.140215       0.193676      -0.034632      -0.019996   \n",
       "1      -0.065833       0.152818       0.050402       0.077813      -0.305431   \n",
       "2       0.067001       0.656415       0.115183      -0.189214      -0.475422   \n",
       "3      -0.162931       0.342772      -0.140089      -0.001462      -0.489326   \n",
       "4      -0.145785       0.218858       0.116727      -0.372996      -0.278894   \n",
       "\n",
       "   embedding_766  embedding_767  \n",
       "0       0.560498       0.340829  \n",
       "1      -0.050150       0.260495  \n",
       "2       0.309695       0.382447  \n",
       "3       0.283278       0.042651  \n",
       "4       0.474181       0.245281  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved dataset\n",
    "df = pd.read_csv('/home/abolfazl/Documents/CitizenJournal/citizen_journal/backend/fastapi_backend/HateSpeech/embedded_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05ce7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: columns embedding_0 to embedding_767\n",
    "X = df[[f'embedding_{i}' for i in range(768)]].values\n",
    "\n",
    "# Labels: assume your label column is 'label'\n",
    "y = df['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc2b9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "638f8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m154/473\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6511 - loss: 0.6206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     27\u001b[39m model.compile(\n\u001b[32m     28\u001b[39m     optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     29\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     30\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    229\u001b[39m lookup_func_type, lookup_func_context = (\n\u001b[32m    230\u001b[39m     function_type_utils.make_canonicalized_monomorphic_type(\n\u001b[32m    231\u001b[39m         args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m )\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m   concrete_function = \u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m   concrete_function = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[39m, in \u001b[36mFunctionCache.lookup\u001b[39m\u001b[34m(self, function_type, context)\u001b[39m\n\u001b[32m     46\u001b[39m context = context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_dict:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m   dispatch_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._primary[(context, dispatch_type)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:80\u001b[39m, in \u001b[36mTypeDispatchTable.dispatch\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the most specific supertype target if it exists in the table.\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# For known exact matches.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_table\u001b[49m:\n\u001b[32m     81\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:460\u001b[39m, in \u001b[36mFunctionType.__hash__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcaptures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/CitizenJournal/citizen_journal/venv/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:154\u001b[39m, in \u001b[36mParameter.__hash__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m    150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m.name, \u001b[38;5;28mself\u001b[39m.kind, \u001b[38;5;28mself\u001b[39m.optional,\n\u001b[32m    151\u001b[39m            \u001b[38;5;28mself\u001b[39m.type_constraint) == (other.name, other.kind, other.optional,\n\u001b[32m    152\u001b[39m                                      other.type_constraint))\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m.name, \u001b[38;5;28mself\u001b[39m.kind, \u001b[38;5;28mself\u001b[39m.optional, \u001b[38;5;28mself\u001b[39m.type_constraint))\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(768,)),\n",
    "    \n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4205\n",
      "Test Accuracy: 0.8028\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6716813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78      2347\n",
      "           1       0.76      0.90      0.82      2375\n",
      "\n",
      "    accuracy                           0.80      4722\n",
      "   macro avg       0.81      0.80      0.80      4722\n",
      "weighted avg       0.81      0.80      0.80      4722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# model.save('/home/abolfazl/Documents/CitizenJournal/citizen_journal/backend/fastapi_backend/HateSpeech/hate_speech_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "740ffda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='/home/abolfazl/Documents/CitizenJournal/citizen_journal/backend/fastapi_backend/HateSpeech/hate_speech_model.keras'\n",
    "\n",
    "from keras.models import load_model\n",
    "model=load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da63934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.95).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e98e74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5493434985175772\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      2347\n",
      "           1       0.98      0.11      0.19      2375\n",
      "\n",
      "    accuracy                           0.55      4722\n",
      "   macro avg       0.75      0.55      0.44      4722\n",
      "weighted avg       0.75      0.55      0.44      4722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8bfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
